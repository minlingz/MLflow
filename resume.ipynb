{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f775ddb6-7daf-4f9f-99fa-7fc024351b47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Training machine learning models on tabular data: Resume\n",
    "\n",
    "It covers the following steps:\n",
    "- Visualize the data using Seaborn and matplotlib\n",
    "- Run a parallel hyperparameter sweep to train machine learning models on the dataset\n",
    "- Explore the results of the hyperparameter sweep with MLflow\n",
    "\n",
    "In this example, I build a model to predict whether the resume owner will receive call back or not based on the resume properties. \n",
    "\n",
    "The example uses a dataset from openintro https://www.openintro.org/data/index.php?data=resume\n",
    "\n",
    "## Requirements\n",
    "This notebook requires Databricks Runtime for Machine Learning.  \n",
    "If you are using Databricks Runtime 7.3 LTS ML, you must update the CloudPickle library. To do that, uncomment and run the `%pip install` command in Cmd 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eab982e-0862-4138-b473-53bfc84bcf48",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\r\n",
      "  Downloading mlflow-2.8.1-py3-none-any.whl (19.0 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/19.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/19.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/19.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/19.0 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/19.0 MB\u001b[0m \u001b[31m153.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.5.2)\r\n",
      "Requirement already satisfied: packaging<24 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (21.3)\r\n",
      "Collecting databricks-cli<1,>=0.8.7\r\n",
      "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/150.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.4)\r\n",
      "Collecting pyyaml<7,>=5.1\r\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/705.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting gunicorn<22\r\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/80.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pytz<2024 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2022.1)\r\n",
      "Requirement already satisfied: pyarrow<15,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.0)\r\n",
      "Collecting cloudpickle<3\r\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\r\n",
      "Collecting Flask<4\r\n",
      "  Downloading flask-3.0.0-py3-none-any.whl (99 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2.28.1)\r\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/lib/python3/dist-packages (from mlflow) (4.6.4)\r\n",
      "Collecting docker<7,>=4.0.0\r\n",
      "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/148.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (0.4)\r\n",
      "Collecting querystring-parser<2\r\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\r\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.19.4)\r\n",
      "Requirement already satisfied: numpy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.21.5)\r\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2.11.3)\r\n",
      "Collecting sqlalchemy<3,>=1.4.0\r\n",
      "  Downloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m174.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sqlparse<1,>=0.4.0\r\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting markdown<4,>=3.3\r\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting gitpython<4,>=2.1.0\r\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/190.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.9.1)\r\n",
      "Requirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.4.4)\r\n",
      "Requirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.1.1)\r\n",
      "Collecting alembic!=1.10.0,<2\r\n",
      "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /databricks/python3/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.3.0)\r\n",
      "Collecting Mako\r\n",
      "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.7 in /databricks/python3/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.11)\r\n",
      "Collecting tabulate>=0.7.7\r\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.0)\r\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\r\n",
      "Collecting websocket-client>=0.32.0\r\n",
      "  Downloading websocket_client-1.6.4-py3-none-any.whl (57 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting blinker>=1.6.2\r\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\r\n",
      "Collecting itsdangerous>=2.1.2\r\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\r\n",
      "Collecting Jinja2<4,>=2.11\r\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/133.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting click<9,>=7.0\r\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting Werkzeug>=3.0.0\r\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\r\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.0.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.25.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2022.9.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (2.2.0)\r\n",
      "Collecting greenlet!=0.4.17\r\n",
      "  Downloading greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/613.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.2/613.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\r\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\r\n",
      "Collecting MarkupSafe>=2.0\r\n",
      "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\n",
      "Installing collected packages: websocket-client, tabulate, sqlparse, smmap, querystring-parser, pyyaml, MarkupSafe, markdown, itsdangerous, greenlet, cloudpickle, click, blinker, Werkzeug, sqlalchemy, Mako, Jinja2, gunicorn, gitdb, docker, databricks-cli, gitpython, Flask, alembic, mlflow\r\n",
      "  Attempting uninstall: MarkupSafe\r\n",
      "    Found existing installation: MarkupSafe 2.0.1\r\n",
      "    Not uninstalling markupsafe at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca\r\n",
      "    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\r\n",
      "  Attempting uninstall: click\r\n",
      "    Found existing installation: click 8.0.4\r\n",
      "    Not uninstalling click at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca\r\n",
      "    Can't uninstall 'click'. No files were found to uninstall.\r\n",
      "  Attempting uninstall: blinker\r\n",
      "    Found existing installation: blinker 1.4\r\n",
      "    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca\r\n",
      "    Can't uninstall 'blinker'. No files were found to uninstall.\r\n",
      "  Attempting uninstall: Jinja2\r\n",
      "    Found existing installation: Jinja2 2.11.3\r\n",
      "    Not uninstalling jinja2 at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca\r\n",
      "    Can't uninstall 'Jinja2'. No files were found to uninstall.\r\n",
      "Successfully installed Flask-3.0.0 Jinja2-3.1.2 Mako-1.3.0 MarkupSafe-2.1.3 Werkzeug-3.0.1 alembic-1.12.1 blinker-1.7.0 click-8.1.7 cloudpickle-2.2.1 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.11 gitpython-3.1.40 greenlet-3.0.1 gunicorn-21.2.0 itsdangerous-2.1.2 markdown-3.5.1 mlflow-2.8.1 pyyaml-6.0.1 querystring-parser-1.2.4 smmap-5.0.1 sqlalchemy-2.0.23 sqlparse-0.4.4 tabulate-0.9.0 websocket-client-1.6.4\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# This command is only required if you are using a cluster running DBR 7.3 LTS ML. \n",
    "#!pip install --upgrade cloudpickle\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f3bfe9-e7a3-4438-9b0e-165c25d4523d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/dbfs/FileStore/shared_uploads/mz246@duke.edu/resume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf5ae58a-d4d4-4006-9a8d-bc7ae8131c12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>received_callback</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>years_college</th>\n",
       "      <th>college_degree</th>\n",
       "      <th>honors</th>\n",
       "      <th>worked_during_school</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>computer_skills</th>\n",
       "      <th>special_skills</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>military</th>\n",
       "      <th>employment_holes</th>\n",
       "      <th>has_email_address</th>\n",
       "      <th>resume_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>black</td>\n",
       "      <td>f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>black</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   received_callback   race  ... has_email_address  resume_quality\n",
       "0                  0  white  ...                 0             low\n",
       "1                  0  white  ...                 1            high\n",
       "2                  0  black  ...                 0             low\n",
       "3                  0  black  ...                 1            high\n",
       "4                  0  white  ...                 1            high\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[:, -16:].drop([\"firstname\"], axis=1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a6af1a1-8a75-4ad5-9920-db0f381222ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>received_callback</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>years_college</th>\n",
       "      <th>college_degree</th>\n",
       "      <th>honors</th>\n",
       "      <th>worked_during_school</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>computer_skills</th>\n",
       "      <th>special_skills</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>military</th>\n",
       "      <th>employment_holes</th>\n",
       "      <th>has_email_address</th>\n",
       "      <th>resume_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   received_callback  race  ...  has_email_address  resume_quality\n",
       "0                  0     1  ...                  0               0\n",
       "1                  0     1  ...                  1               1\n",
       "2                  0     0  ...                  0               0\n",
       "3                  0     0  ...                  1               1\n",
       "4                  0     1  ...                  1               1\n",
       "5                  0     1  ...                  0               0\n",
       "6                  0     1  ...                  1               1\n",
       "7                  0     0  ...                  1               1\n",
       "8                  0     0  ...                  0               0\n",
       "9                  0     0  ...                  1               1\n",
       "\n",
       "[10 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"race\"] = data[\"race\"].apply(lambda x: 1 if x == \"white\" else 0)\n",
    "data[\"resume_quality\"] = data[\"resume_quality\"].apply(lambda x: 1 if x == \"high\" else 0)\n",
    "data[\"gender\"] = data[\"gender\"].apply(lambda x: 1 if x == \"f\" else 0)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27b6967c-5a25-4fe6-894c-4c07a63014d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Preprocess data\n",
    "Prior to training a model, check for missing values and split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "601c2717-c8a5-4411-ba78-e033a9bcdd83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aff3310f-e556-44b6-8f7d-e547682e7677",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "379abb9a-bd5b-46b9-8975-ce91858eba39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Prepare dataset for training baseline model\n",
    "Split the input data into 3 sets:\n",
    "- Train (60% of the dataset used to train the model)\n",
    "- Validation (20% of the dataset used to tune the hyperparameters)\n",
    "- Test (20% of the dataset used to report the true performance of the model on an unseen dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e70c1c07-0048-4bb8-a0c3-17a7895bb4b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop([\"received_callback\"], axis=1)\n",
    "y = data.received_callback\n",
    "\n",
    "# Split out the training data\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(\n",
    "    X, y, train_size=0.6, random_state=123\n",
    ")\n",
    "\n",
    "# Split the remaining data equally into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_rem, y_rem, test_size=0.5, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "224d0ddf-3925-4849-bc20-564175c212e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Build a baseline model\n",
    "This task seems well suited to a random forest classifier, since the output is binary and there may be interactions between multiple variables.\n",
    "\n",
    "The following code builds a simple classifier using scikit-learn. It uses MLflow to keep track of the model accuracy, and to save the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15380e3d-6b76-4223-8eac-43ab92cf65a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa8fbff-53a9-4eea-a77b-0708b83273a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/24 02:17:56 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/11/24 02:17:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/11/24 02:17:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/databricks/python/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2023/11/24 02:17:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/11/24 02:17:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "import cloudpickle\n",
    "import time\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# The predict method of sklearn's RandomForestClassifier returns a binary classification (0 or 1).\n",
    "# The following code creates a wrapper function, SklearnModelWrapper, that uses\n",
    "# the predict_proba method to return the probability that the observation belongs to each class.\n",
    "\n",
    "\n",
    "class SklearnModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        return self.model.predict_proba(model_input)[:, 1]\n",
    "\n",
    "\n",
    "# mlflow.start_run creates a new MLflow run to track the performance of this model.\n",
    "# Within the context, you call mlflow.log_param to keep track of the parameters used, and\n",
    "# mlflow.log_metric to record metrics like accuracy.\n",
    "# mlflow.create_experiment(\"mzExperiment\")\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=\"untuned_random_forest\",\n",
    "    experiment_id=mlflow.get_experiment_by_name(\"mzExperiment\").experiment_id,\n",
    "):\n",
    "    n_estimators = 10\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, random_state=np.random.RandomState(123)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict_proba returns [prob_negative, prob_positive], so slice the output with [:, 1]\n",
    "    predictions_test = model.predict_proba(X_test)[:, 1]\n",
    "    auc_score = roc_auc_score(y_test, predictions_test)\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    # Use the area under the ROC curve as a metric.\n",
    "    mlflow.log_metric(\"auc\", auc_score)\n",
    "    wrappedModel = SklearnModelWrapper(model)\n",
    "    # Log the model with a signature that defines the schema of the model's inputs and outputs.\n",
    "    # When the model is deployed, this signature will be used to validate inputs.\n",
    "    signature = infer_signature(X_train, wrappedModel.predict(None, X_train))\n",
    "\n",
    "    # MLflow contains utilities to create a conda environment used to serve models.\n",
    "    # The necessary dependencies are added to a conda.yaml file which is logged along with the model.\n",
    "    conda_env = _mlflow_conda_env(\n",
    "        additional_conda_deps=None,\n",
    "        additional_pip_deps=[\n",
    "            \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
    "            \"scikit-learn=={}\".format(sklearn.__version__),\n",
    "        ],\n",
    "        additional_conda_channels=None,\n",
    "    )\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"random_forest_model\",\n",
    "        python_model=wrappedModel,\n",
    "        conda_env=conda_env,\n",
    "        signature=signature,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "867b3e23-9147-4ca4-b2d2-f1103c471d53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Examine the learned feature importances output by the model as a sanity-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e174abe-774b-461e-b390-212e11d1c68d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>years_experience</th>\n",
       "      <td>0.424431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.085594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worked_during_school</th>\n",
       "      <td>0.063321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_skills</th>\n",
       "      <td>0.062062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.057090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volunteer</th>\n",
       "      <td>0.051227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer_skills</th>\n",
       "      <td>0.050512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_holes</th>\n",
       "      <td>0.045791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_college</th>\n",
       "      <td>0.039595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honors</th>\n",
       "      <td>0.032277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_email_address</th>\n",
       "      <td>0.025542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college_degree</th>\n",
       "      <td>0.024520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.021261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resume_quality</th>\n",
       "      <td>0.016777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "years_experience        0.424431\n",
       "race                    0.085594\n",
       "worked_during_school    0.063321\n",
       "special_skills          0.062062\n",
       "gender                  0.057090\n",
       "volunteer               0.051227\n",
       "computer_skills         0.050512\n",
       "employment_holes        0.045791\n",
       "years_college           0.039595\n",
       "honors                  0.032277\n",
       "has_email_address       0.025542\n",
       "college_degree          0.024520\n",
       "military                0.021261\n",
       "resume_quality          0.016777"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    model.feature_importances_, index=X_train.columns.tolist(), columns=[\"importance\"]\n",
    ")\n",
    "feature_importances.sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b56f380-2846-4644-a67a-3a389d88dccf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5325833586703153\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Set the value of 'run_name'\n",
    "run_name = \"untuned_random_forest\"\n",
    "\n",
    "# Retrieve the run ID for the run\n",
    "# Assumes that you have already set the experiment ID and 'run_name' parameter\n",
    "search_results = mlflow.search_runs(\n",
    "    experiment_ids=mlflow.get_experiment_by_name(\"mzExperiment\").experiment_id,\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    filter_string=f\"tags.mlflow.runName = '{run_name}'\",\n",
    ")\n",
    "run_id = search_results.loc[search_results[\"tags.mlflow.runName\"] == run_name][\n",
    "    \"run_id\"\n",
    "].iloc[0]\n",
    "\n",
    "# Retrieve the AUC metric value from the run\n",
    "run = mlflow.get_run(run_id)\n",
    "auc = run.data.metrics[\"auc\"]\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d1df4d8-4b50-47d8-ad89-d3c80ce960ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Register the model in MLflow Model Registry\n",
    "\n",
    "By registering this model in Model Registry, you can easily reference the model from anywhere within Databricks.\n",
    "\n",
    "The following section shows how to do this programmatically, but you can also register a model using the UI. See \"Create or register a model using the UI\" ([AWS](https://docs.databricks.com/applications/machine-learning/manage-model-lifecycle/index.html#create-or-register-a-model-using-the-ui)|[Azure](https://docs.microsoft.com/azure/databricks/applications/machine-learning/manage-model-lifecycle/index#create-or-register-a-model-using-the-ui)|[GCP](https://docs.gcp.databricks.com/applications/machine-learning/manage-model-lifecycle/index.html#create-or-register-a-model-using-the-ui))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4774edbf-f3fb-495c-a638-ec63f275f885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'resume'.\n",
      "2023/11/24 02:29:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: resume, version 1\n",
      "Created version '1' of model 'resume'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resume\"\n",
    "model_version = mlflow.register_model(f\"runs:/{run_id}/random_forest_model\", model_name)\n",
    "\n",
    "# Registering the model takes a few seconds, so add a small delay\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb032bd6-7e9d-4430-8c13-895ebc189297",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1700792946796, current_stage='Production', description='', last_updated_timestamp=1700793013666, name='resume', run_id='243bb223af0c4bc682493a54ab9eecec', run_link='', source='mlflow-artifacts:/438529569510626367/243bb223af0c4bc682493a54ab9eecec/artifacts/random_forest_model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version.version,\n",
    "    stage=\"Production\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f284978e-9c9b-4cd2-8bdc-1393991c5701",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The Models page now shows the model version in stage \"Production\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58b22211-62ea-4fdd-a6ff-c552a65fa6e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/24 02:30:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-2df73871-3175-4be4-8c95-414efb8964ca/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5325833586703153\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(f\"models:/{model_name}/production\")\n",
    "\n",
    "# Sanity-check: This should match the AUC logged by MLflow\n",
    "print(f\"AUC: {roc_auc_score(y_test, model.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bc8e62b-0ee7-42bf-838a-45c020259814",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Experiment with a new model\n",
    "\n",
    "The random forest model performed well even without hyperparameter tuning.\n",
    "\n",
    "The following code uses the xgboost library to train a more accurate model. It runs a parallel hyperparameter sweep to train multiple\n",
    "models in parallel, using Hyperopt and SparkTrials. As before, the code tracks the performance of each parameter configuration with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f69756-98aa-4e0e-b8bf-0a7d84dbdb05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/96 [00:00<?, ?trial/s, best loss=?]\r  2%|▏         | 2/96 [00:20<15:41, 10.02s/trial, best loss: -0.6380017499726567]\r  3%|▎         | 3/96 [00:21<09:42,  6.27s/trial, best loss: -0.6380017499726567]\r  4%|▍         | 4/96 [00:22<06:35,  4.30s/trial, best loss: -0.6380017499726567]\r  6%|▋         | 6/96 [00:38<09:19,  6.22s/trial, best loss: -0.6380017499726567]\r  8%|▊         | 8/96 [00:39<05:33,  3.79s/trial, best loss: -0.6380017499726567]\r 10%|█         | 10/96 [00:56<07:59,  5.57s/trial, best loss: -0.6380017499726567]\r 12%|█▎        | 12/96 [00:58<05:33,  3.97s/trial, best loss: -0.6380017499726567]\r 14%|█▎        | 13/96 [01:14<08:50,  6.39s/trial, best loss: -0.6380017499726567]\r 15%|█▍        | 14/96 [01:15<07:05,  5.19s/trial, best loss: -0.6380017499726567]\r 17%|█▋        | 16/96 [01:16<04:29,  3.37s/trial, best loss: -0.6389656020999672]\r 18%|█▊        | 17/96 [01:32<08:03,  6.13s/trial, best loss: -0.6389656020999672]\r 19%|█▉        | 18/96 [01:33<06:23,  4.91s/trial, best loss: -0.6389656020999672]\r 21%|██        | 20/96 [01:34<03:58,  3.14s/trial, best loss: -0.6389656020999672]\r 25%|██▌       | 24/96 [01:51<04:29,  3.74s/trial, best loss: -0.640647216449743] \r 29%|██▉       | 28/96 [02:09<04:37,  4.08s/trial, best loss: -0.640647216449743]\r 33%|███▎      | 32/96 [02:27<04:31,  4.25s/trial, best loss: -0.640647216449743]\r 38%|███▊      | 36/96 [02:45<04:20,  4.34s/trial, best loss: -0.640647216449743]\r 42%|████▏     | 40/96 [03:03<04:06,  4.40s/trial, best loss: -0.640647216449743]\r 46%|████▌     | 44/96 [03:21<03:50,  4.44s/trial, best loss: -0.640647216449743]\r 50%|█████     | 48/96 [03:39<03:34,  4.46s/trial, best loss: -0.640647216449743]\r 54%|█████▍    | 52/96 [03:57<03:17,  4.48s/trial, best loss: -0.640647216449743]\r 58%|█████▊    | 56/96 [04:15<02:59,  4.49s/trial, best loss: -0.640647216449743]\r 62%|██████▎   | 60/96 [04:32<02:39,  4.42s/trial, best loss: -0.640647216449743]\r 64%|██████▎   | 61/96 [04:51<03:21,  5.77s/trial, best loss: -0.640647216449743]\r 70%|██████▉   | 67/96 [04:56<01:41,  3.51s/trial, best loss: -0.6430055780378432]\r 73%|███████▎  | 70/96 [05:01<01:19,  3.06s/trial, best loss: -0.6430055780378432]\r 74%|███████▍  | 71/96 [05:08<01:27,  3.48s/trial, best loss: -0.6430055780378432]\r 75%|███████▌  | 72/96 [05:14<01:31,  3.82s/trial, best loss: -0.6430055780378432]\r 76%|███████▌  | 73/96 [05:16<01:21,  3.53s/trial, best loss: -0.6430055780378432]\r 77%|███████▋  | 74/96 [05:18<01:11,  3.26s/trial, best loss: -0.6430055780378432]\r 79%|███████▉  | 76/96 [05:19<00:46,  2.31s/trial, best loss: -0.6430055780378432]\r 80%|████████  | 77/96 [05:24<00:54,  2.85s/trial, best loss: -0.6430055780378432]\r 84%|████████▍ | 81/96 [05:27<00:26,  1.74s/trial, best loss: -0.6430055780378432]\r 85%|████████▌ | 82/96 [05:31<00:29,  2.11s/trial, best loss: -0.6430055780378432]\r 86%|████████▋ | 83/96 [05:33<00:27,  2.10s/trial, best loss: -0.6430055780378432]\r 88%|████████▊ | 84/96 [05:34<00:22,  1.87s/trial, best loss: -0.6430055780378432]\r 89%|████████▊ | 85/96 [05:35<00:18,  1.67s/trial, best loss: -0.6430055780378432]\r 90%|████████▉ | 86/96 [05:36<00:15,  1.51s/trial, best loss: -0.6430055780378432]\r 91%|█████████ | 87/96 [05:40<00:19,  2.16s/trial, best loss: -0.6430055780378432]\r 92%|█████████▏| 88/96 [05:42<00:16,  2.12s/trial, best loss: -0.6430055780378432]\r 93%|█████████▎| 89/96 [05:45<00:16,  2.37s/trial, best loss: -0.6443317291917314]\r 94%|█████████▍| 90/96 [05:47<00:13,  2.26s/trial, best loss: -0.6443317291917314]\r 98%|█████████▊| 94/96 [05:49<00:02,  1.17s/trial, best loss: -0.6443317291917314]\r 99%|█████████▉| 95/96 [05:51<00:01,  1.32s/trial, best loss: -0.6443317291917314]\r100%|██████████| 96/96 [05:54<00:00,  1.67s/trial, best loss: -0.6443317291917314]\r100%|██████████| 96/96 [05:54<00:00,  3.69s/trial, best loss: -0.6443317291917314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt-spark:Total Trials: 96: 96 succeeded, 0 failed, 0 cancelled.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "from math import exp\n",
    "import mlflow.xgboost\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "search_space = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 4, 100, 1)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", -3, 0),\n",
    "    \"reg_alpha\": hp.loguniform(\"reg_alpha\", -5, -1),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", -6, -1),\n",
    "    \"min_child_weight\": hp.loguniform(\"min_child_weight\", -1, 3),\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"seed\": 123,  # Set a seed for deterministic training\n",
    "}\n",
    "\n",
    "\n",
    "def train_model(params):\n",
    "    # With MLflow autologging, hyperparameters and the trained model are automatically logged to MLflow.\n",
    "    mlflow.xgboost.autolog()\n",
    "    with mlflow.start_run(nested=True):\n",
    "        train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "        validation = xgb.DMatrix(data=X_val, label=y_val)\n",
    "        # Pass in the validation set so xgb can track an evaluation metric. XGBoost terminates training when the evaluation metric\n",
    "        # is no longer improving.\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(validation, \"validation\")],\n",
    "            early_stopping_rounds=50,\n",
    "        )\n",
    "        validation_predictions = booster.predict(validation)\n",
    "        auc_score = roc_auc_score(y_val, validation_predictions)\n",
    "        mlflow.log_metric(\"auc\", auc_score)\n",
    "\n",
    "        signature = infer_signature(X_train, booster.predict(train))\n",
    "        mlflow.xgboost.log_model(booster, \"model\", signature=signature)\n",
    "\n",
    "        # Set the loss to -1*auc_score so fmin maximizes the auc_score\n",
    "        return {\n",
    "            \"status\": STATUS_OK,\n",
    "            \"loss\": -1 * auc_score,\n",
    "            \"booster\": booster.attributes(),\n",
    "        }\n",
    "\n",
    "\n",
    "# Greater parallelism will lead to speedups, but a less optimal hyperparameter sweep.\n",
    "# A reasonable value for parallelism is the square root of max_evals.\n",
    "spark_trials = SparkTrials(parallelism=10)\n",
    "\n",
    "# Run fmin within an MLflow run context so that each hyperparameter configuration is logged as a child run of a parent\n",
    "# run called \"xgboost_models\" .\n",
    "with mlflow.start_run(\n",
    "    run_name=\"xgboost_models\",\n",
    "    experiment_id=mlflow.get_experiment_by_name(\"mzExperiment\").experiment_id,\n",
    "):\n",
    "    best_params = fmin(\n",
    "        fn=train_model,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=96,\n",
    "        trials=spark_trials,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "012e3c74-236f-4166-bb15-b129eb01181a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Use MLflow to view the results\n",
    "Open up the Experiment Runs sidebar to see the MLflow runs. Click on Date next to the down arrow to display a menu, and select 'auc' to display the runs sorted by the auc metric. The highest auc value is 0.64.\n",
    "\n",
    "MLflow tracks the parameters and performance metrics of each run. Click the External Link icon <img src=\"https://docs.databricks.com/_static/images/icons/external-link.png\"/> at the top of the Experiment Runs sidebar to navigate to the MLflow Runs Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00e5ea89-0918-44b3-9fca-60f7f48fb6b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now investigate how the hyperparameter choice correlates with AUC. Click the \"+\" icon to expand the parent run, then select all runs except the parent, and click \"Compare\". Select the Parallel Coordinates Plot.\n",
    "\n",
    "The Parallel Coordinates Plot is useful in understanding the impact of parameters on a metric. You can drag the pink slider bar at the upper right corner of the plot to highlight a subset of AUC values and the corresponding parameter values. The plot below highlights the highest AUC values:\n",
    "\n",
    "<img src=\"pc_h.png\"/>\n",
    "\n",
    "Notice that all of the top performing runs have a low value for reg_lambda and learning_rate. \n",
    "\n",
    "You could run another hyperparameter sweep to explore even lower values for these parameters. For simplicity, that step is not included in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c34b4cf8-35f1-48e8-bc64-51b6b4cf0f70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Update the production `resume` model in MLflow Model Registry\n",
    "\n",
    "Earlier, you saved the baseline model to Model Registry with the name `resume`. Now that you have a created a more accurate model, update `resume`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7419396-4da9-4181-8a3d-613b80d3544b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'resume' already exists. Creating a new version of this model...\n",
      "2023/11/24 03:28:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: resume, version 2\n",
      "Created version '2' of model 'resume'.\n"
     ]
    }
   ],
   "source": [
    "new_model_version = mlflow.register_model(f\"runs:/{best_run.run_id}/model\", model_name)\n",
    "\n",
    "# Registering the model takes a few seconds, so add a small delay\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faaceaa1-fb8c-4e72-80c6-b9c7c5815a18",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Click **Models** in the left sidebar to see that the `resume` model now has two versions. \n",
    "\n",
    "The following code promotes the new version to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c2eaec-eaf5-4e38-ab58-1d029271e4b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1700796492421, current_stage='Production', description='', last_updated_timestamp=1700796514375, name='resume', run_id='243bb223af0c4bc682493a54ab9eecec', run_link='', source='mlflow-artifacts:/438529569510626367/243bb223af0c4bc682493a54ab9eecec/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Archive the old model version\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name, version=model_version.version, stage=\"Archived\"\n",
    ")\n",
    "\n",
    "# Promote the new model version to Production\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name, version=new_model_version.version, stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11553e11-faea-43ae-aac1-10545a252e64",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Clients that call load_model now receive the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "383276bc-bdfe-416f-956d-c45773af7a00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The auc value on the test set for the new model is 0.64. It beat the baseline!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "resume",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
